ğŸ§  Understanding Support Vector Machines, One Margin at a Time

(End-to-End SVM Implementation using scikit-learn)

ğŸŒŸ Project Overview

This project demonstrates a complete, end-to-end implementation of Support Vector Machines (SVM) using scikit-learn, with a strong focus on conceptual clarity.

It goes beyond .fit() and .predict() to show how SVM actually works, including:

Margin construction

Support vector identification

Non-linear decision boundaries using the RBF kernel

ğŸ¯ What This Project Aims to Do

Build Linear and RBF SVM classifiers

Show why feature scaling is mandatory

Visualize:

Decision boundary

Margin

Support vectors

Explain the effect of hyperparameters (C, gamma)

Help learners see what SVM is doing internally

ğŸ§© Key Concepts Covered

ğŸ“ Maximum-margin hyperplane

ğŸ¯ Support vectors (the only points that matter)

ğŸ” Kernel trick for non-linear separation

âš–ï¸ Biasâ€“variance tradeoff using C

ğŸŒŠ Boundary smoothness controlled by gamma

ğŸ› ï¸ Tech Stack

ğŸ Python 3.8+

ğŸ“¦ scikit-learn

ğŸ“Š NumPy

ğŸ“‰ Matplotlib

ğŸ“‚ Project Structure
.
â”œâ”€â”€ svm_sklearn.py     # Complete SVM pipeline (training + visualization)
â”œâ”€â”€ README.md          # Project documentation
â–¶ï¸ How to Run the Project
1ï¸âƒ£ Install dependencies
pip install numpy matplotlib scikit-learn
2ï¸âƒ£ Run the script
python svm_sklearn.py
ğŸ“Š Output Youâ€™ll See

ğŸ”µğŸ”´ Data points from two classes

â– Solid curve â†’ Decision boundary

â–â– Dashed curves â†’ Margin boundaries

â­• Circled points â†’ Support vectors

ğŸ“Œ The curved boundary appears because the RBF kernel maps data into a higher-dimensional space where separation becomes linear.

âš™ï¸ Hyperparameters Explained
ğŸ”§ C â€“ Regularization Strength

High C â†’ smaller margin, fewer errors, overfitting risk

Low C â†’ wider margin, more errors, underfitting risk

ğŸ”§ gamma â€“ Kernel Influence

High gamma â†’ very complex, wiggly boundary

Low gamma â†’ smoother, simpler boundary

ğŸš« Common Mistakes This Project Avoids

âŒ Training SVM without scaling features

âŒ Blindly using RBF kernel

âŒ Ignoring support vectors

âŒ Evaluating only on training data

ğŸ‘¨â€ğŸ“ Who This Project Is For

Students learning Machine Learning fundamentals

Engineers who want intuition + implementation

Interview preparation (conceptual depth)

Anyone tired of black-box ML
